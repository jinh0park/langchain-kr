{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ê³µë¶€í•˜ê¸°\n",
    "\n",
    "í…Œë”” ë…¸íŠ¸ë‹˜ì˜ [<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·](https://wikidocs.net/book/14314)ë¥¼ ë³´ë©´ì„œ LangChainì„ ê³µë¶€í•˜ê³  ìˆë‹¤. Prompt Engineeringì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ê³µë¶€ë¥¼ í•´ë³´ë‹ˆ ì´ë¥¼ ì§ì ‘ ì ìš©í•˜ì—¬ LLMì„ í™œìš©í•˜ê³  ì‹¶ì–´ì¡Œê³ , ì´ë¥¼ ìœ„í•´ì„œëŠ” LangChainì´ë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìµí í•„ìš”ê°€ ìˆë‹¤ê³  ìƒê°í–ˆë‹¤.\n",
    "\n",
    "í™•ì‹¤íˆ ë§Œë“¤ì–´ì§„ì§€ ì–¼ë§ˆ ì•ˆ ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹ˆë§Œí¼ ì˜¤ë¥˜ë„ ë§ê³ , ìˆ˜ì •ë„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤. êµ¬ê¸€ë§ì„ í•´ë´ë„ ë„ëŒ€ì²´ ì›ì¸ì„ ì•Œ ìˆ˜ê°€ ì—†ì–´ì„œ LangChain Github Repoë¥¼ ë“¤ì–´ê°€ë³´ë‚˜ 13ì‹œê°„ ì „ì— ì˜¤ë¥˜ê°€ ìˆ˜ì •ë˜ì–´ ìˆë‹¤ë“ ê°€... ì—¬í•˜íŠ¼ ê³µë¶€ë„ ì¬ë°Œì§€ë§Œ ì´ëŸ° ì´ˆì°½ê¸° í”„ë¡œì íŠ¸ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ë³´ëŠ” ê²½í—˜ ìì²´ê°€ ì‹ ë¹„ë¡­ë‹¤.\n",
    "\n",
    "ì´ëŸ° ê°œë°œ ê´€ë ¨ ë¸”ë¡œê·¸ëŠ” Ipython Notebookìœ¼ë¡œ ì‘ì„±í•˜ê³  ì ë‹¹íˆ ë‹¤ë“¬ì€ í›„ (ì´ê²ƒë„ LLMìœ¼ë¡œ ê°€ëŠ¥!) ì˜¬ë¦¬ëŠ”ê²Œ ê½¤ ê´œì°®ì€ ë°©ë²•ì¸ ê²ƒ ê°™ë‹¤. ë§ˆì¹¨ í…Œë”” ë…¸íŠ¸ë‹˜ì´ í•´ë‹¹ ë°©ë²•ë¡ ì— ëŒ€í•œ ê°€ì´ë“œë„ ë§Œë“¤ì–´ì£¼ì…”ì„œ ë³´ê³  ì ìš©í•´ë³´ë ¤ í•œë‹¤. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ ì„¸íŒ…\n",
    "\n",
    "`langchain`ì„ `pip`ë¡œ ì„¤ì¹˜í•´ì£¼ê¸°ë§Œ í•˜ë©´ ëœë‹¤. `langsmith` ì„¤ì •ì€ ë‚˜ì¤‘ì— í•„ìš”ì„±ì„ ëŠë‚„ ë•Œ í•´ë„ ëŠ¦ì§€ ì•Šì„ ê²ƒ ê°™ì•„ì„œ ìƒëµí–ˆë‹¤.\n",
    "\n",
    "LLMì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ê° ì„œë¹„ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” API_KEYë¥¼ ë°œê¸‰ ë°›ì•„ì•¼ í•œë‹¤. ì´ë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì €ì¥í•´ë‘ë©´ ë”°ë¡œ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬í•˜ì§€ ì•Šê³  í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "í…Œë””ë…¸íŠ¸ì—ì„œëŠ” `dotenv`ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ë‚˜ëŠ” ê·¸ëƒ¥ ê·€ì°®ì•„ì„œ  `.zprofile`ì— (zsh ê¸°ì¤€)ì— ë“±ë¡í–ˆë‹¤. ì£¼ìš” ì„œë¹„ìŠ¤ ë³„ keyëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "\n",
    "- OpenAI: `OPENAI_API_KEY`\n",
    "- Google Gemini: `GOOGLE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë‹µë³€]: content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-4202b29e-4843-4a65-9de9-4591dc0852d3-0' usage_metadata={'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°ì²´ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o-mini\",  # ëª¨ë¸ëª…\n",
    ")\n",
    "\n",
    "# ì§ˆì˜ë‚´ìš©\n",
    "question = \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# ì§ˆì˜\n",
    "print(f\"[ë‹µë³€]: {llm.invoke(question)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainê³¼ LCEL(LangChain Expression Language) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o-mini\",  # ëª¨ë¸ëª…\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ì ìœ¼ë¡œ `chain`ì€ `prompt`, `model`, `parser`ì˜ sequentialë¡œ ì´ë£¨ì–´ì§„ë‹¤. ê° ìš”ì†ŒëŠ” ìš©ë„ì— ë”°ë¼ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ë¡œ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í•„ìš”ì— ë”°ë¼ ì ì ˆíˆ ê°€ì ¸ë‹¤ ì“¸ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['country'], template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?') middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10e60bc50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10e617590>, model_name='gpt-4o-mini', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')] last=StrOutputParser()\n",
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(chain)\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íƒ€ì…ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ `chain`ì€ `Runnable`ì˜ sequenceì´ë‹¤. `prompt`, `model`, `parser`ë„ íŠ¹ì •í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ê³  ìˆëŠ” `Runnable`ì˜ í•œ ì¢…ë¥˜ì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì•„ë˜ ì½”ë“œì—ì„œ ê° ìš”ì†Œë“¤ë„ ê°œë³„ì ìœ¼ë¡œ `invoke()` methodë¥¼ í˜¸ì¶œ ê°€ëŠ¥í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?'\n",
      "content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 13, 'total_tokens': 21}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-9c6f9ff5-699c-40ef-ac25-28cc70f33f5a-0' usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21}\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"}))\n",
    "output = llm.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?\")\n",
    "print(output)\n",
    "print(output_parser.invoke(output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable\n",
    "\n",
    "chainì„ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬ì„±í•˜ê¸° ìœ„í•´ ì—°ê²°ê³ ë¦¬ ì—­í• ì„ í•˜ëŠ” `Runnable` ê°ì²´ë“¤ì´ ìˆë‹¤.\n",
    "\n",
    "- `RunnablePassThrough`\n",
    "- `RunnableParalle`\n",
    "- `RunnableLambda`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassThrough"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ ë‘ ì½”ë“œëŠ” ì™„ì „íˆ ë™ì¼í•˜ë‹¤. ì¦‰, `dict`ë¥¼ chainì— í¬í•¨ì‹œí‚¤ê³ ì í•  ë•Œ `RunnablePassThrough`ë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\n",
    "    prompt.invoke({\"country\":\"ëŒ€í•œë¯¼êµ­\"}) ==\n",
    "    ({\"country\": RunnablePassthrough()} | prompt).invoke(\"ëŒ€í•œë¯¼êµ­\")\n",
    ")\n",
    "\n",
    "prompt.invoke({\"country\":\"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assign()` methodë¥¼ ì´ìš©í•˜ì—¬, inputìœ¼ë¡œ ë°›ì€ `dict`ì— ìƒˆë¡œìš´ í‚¤-ë°¸ë¥˜ ìŒì„ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'ëŒ€í•œë¯¼êµ­', 'city': 'ì„œìš¸', 'address': 'ëŒ€í•œë¯¼êµ­ ì„œìš¸'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì…ë ¥ í‚¤: num, í• ë‹¹(assign) í‚¤: new_num\n",
    "(RunnablePassthrough.assign(address=lambda x: x[\"country\"] + \" \" +  x[\"city\"])).invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\", \"city\": \"ì„œìš¸\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableParallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableParallel`ì€ inputì„ ë°›ìœ¼ë©´, ì´ë¥¼ ì§€ì •í•œ parameter ìˆ˜ ë§Œí¼ì˜ `Runnable`(ë˜ëŠ” callable, dict)ì— ì „ë‹¬í•˜ì—¬ ë¶„ê¸°ì ì„ í˜•ì„±í•˜ëŠ” ê°ì²´ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out1': 1, 'out2': 2, 'out3': 3}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "RunnableParallel(out1=lambda x: x, out2=lambda x:x+1, out3=lambda x:x+2).invoke(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableParallel`ì„ ì´ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ chainì„ ë³‘ë ¬ì ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "`RunnableParallel`ë¡œ chainì„ ì—°ê²°í•  ê²½ìš° ë³‘ë ¬ì²˜ë¦¬ë˜ì–´ ì‹¤í–‰ì‹œê°„ë©´ì—ì„œ ì´ë“ì„ ë³¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o\",  # ëª¨ë¸ëª…\n",
    ")\n",
    "\n",
    "chain1 = PromptTemplate.from_template(\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\") | llm | StrOutputParser()\n",
    "chain2 = PromptTemplate.from_template(\"{country}ì˜ ì¸êµ¬ëŠ” ëª‡ ëª…ì…ë‹ˆê¹Œ?\") | llm | StrOutputParser()\n",
    "chain3 = PromptTemplate.from_template(\"{country}ì˜ ë©´ì ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?\") | llm | StrOutputParser()\n",
    "\n",
    "combined_chain = ({\"country\": RunnablePassthrough()} \n",
    "                  | RunnableParallel(capital=chain1, population=chain2, area=chain3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'population': '2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì˜ ì¸êµ¬ëŠ” ì•½ 5,100ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸êµ¬ëŠ” ì§€ì†ì ìœ¼ë¡œ ë³€ë™í•˜ë¯€ë¡œ, ìµœì‹  í†µê³„ëŠ” ëŒ€í•œë¯¼êµ­ í†µê³„ì²­ì´ë‚˜ ê´€ë ¨ ê¸°ê´€ì˜ ê³µì‹ ìë£Œë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.',\n",
       " 'area': 'ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,210 í‰ë°©í‚¬ë¡œë¯¸í„°ì…ë‹ˆë‹¤. ì´ëŠ” í•œë°˜ë„ì˜ ë‚¨ìª½ ë¶€ë¶„ì— í•´ë‹¹í•˜ë©°, ë¶í•œê³¼ í•¨ê»˜ í•œë°˜ë„ë¥¼ êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain.invoke(\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableLambda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableLambda`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ë§µí•‘í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì…ë ¥ ë³€ìˆ˜ê°€ í•„ìš”í•˜ì§€ ì•Šì€ í•¨ìˆ˜ì˜ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aug-04'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "print(get_today(None))\n",
    "\n",
    "RunnableLambda(get_today).invoke(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì…ë ¥ ë³€ìˆ˜ê°€ 1ê°œì¸ í•¨ìˆ˜ì˜ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "print(get_text_length(\"pizza\"))\n",
    "\n",
    "RunnableLambda(get_text_length).invoke(\"pizza\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì…ë ¥ ë³€ìˆ˜ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°, ì¸ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ í•˜ë‚˜ë¡œ ë°›ì•„ì„œ ì› í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” í˜•íƒœì˜ wrapping í•¨ìˆ˜ë¥¼ ì¬ì •ì˜í•˜ì—¬ í™œìš©í•´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potato-pizza\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'potato-pizza'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_text(text1, text2):\n",
    "    return text1 + \"-\" + text2\n",
    "\n",
    "def _concat_text(_dict):\n",
    "    return concat_text(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "print(concat_text(\"potato\", \"pizza\"))\n",
    "\n",
    "RunnableLambda(_concat_text).invoke({\"text1\":\"potato\", \"text2\":\"pizza\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "êµ³ì´ í•¨ìˆ˜ë¥¼ ì¬ì •ì˜í•˜ì§€ ì•Šê³  unpacking ì—°ì‚°ìì™€ lambdaë¥¼ í™œìš©í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'potato-pizza'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_text(text1, text2):\n",
    "    return text1 + \"-\" + text2\n",
    "\n",
    "RunnableLambda(lambda _: concat_text(**_)).invoke({\"text1\":\"potato\", \"text2\":\"pizza\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ì™€ ê°™ì´ í™œìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ë¬¼ë¡ ì…ë‹ˆë‹¤! 8ì›” 4ì¼ì— ê°€ê¹Œìš´ ê¸°ë…ì¼ë“¤ì„ ë‚˜ì—´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤:\n",
       "\n",
       "1. **8ì›” 1ì¼**: \n",
       "   - ìŠ¤ìœ„ìŠ¤ êµ­ê²½ì¼ (Swiss National Day)\n",
       "   - ì„¸ê³„ ëª¨ìœ  ìˆ˜ìœ  ì£¼ê°„ (World Breastfeeding Week, 8ì›” 1ì¼ ~ 7ì¼)\n",
       "\n",
       "2. **8ì›” 6ì¼**: \n",
       "   - íˆë¡œì‹œë§ˆ ì›í­ íˆ¬í•˜ ê¸°ë…ì¼ (Hiroshima Peace Memorial Ceremony)\n",
       "\n",
       "3. **8ì›” 7ì¼**: \n",
       "   - í¼í”Œ í•˜íŠ¸ ë°ì´ (Purple Heart Day, ë¯¸êµ­)\n",
       "\n",
       "4. **8ì›” 9ì¼**: \n",
       "   - ë‚˜ê°€ì‚¬í‚¤ ì›í­ íˆ¬í•˜ ê¸°ë…ì¼ (Nagasaki Peace Memorial Ceremony)\n",
       "   - ì„¸ê³„ ì›ì£¼ë¯¼ì˜ ë‚  (International Day of the World's Indigenous Peoples)\n",
       "\n",
       "ì´ ì™¸ì—ë„ ê° ë‚˜ë¼ë‚˜ ì§€ì—­ì— ë”°ë¼ ë‹¤ì–‘í•œ ê¸°ë…ì¼ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • êµ­ê°€ë‚˜ ë¬¸í™”ì— ê´€ë ¨ëœ ê¸°ë…ì¼ì„ ì•Œê³  ì‹¶ìœ¼ì‹œë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today)}\n",
    "    | PromptTemplate.from_template(\"{today}ì— ê°€ê¹Œìš´ ê¸°ë…ì¼ì„ ë‚˜ì—´í•´ì¤˜\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "display(Markdown(chain.invoke(\"\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
