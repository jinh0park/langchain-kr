{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 공부하기\n",
    "\n",
    "테디 노트님의 [<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷](https://wikidocs.net/book/14314)를 보면서 LangChain을 공부하고 있다. Prompt Engineering에 대해 간단하게 공부를 해보니 이를 직접 적용하여 LLM을 활용하고 싶어졌고, 이를 위해서는 LangChain이라는 라이브러리를 익힐 필요가 있다고 생각했다.\n",
    "\n",
    "확실히 만들어진지 얼마 안 된 라이브러리이니만큼 오류도 많고, 수정도 실시간으로 이루어진다. 구글링을 해봐도 도대체 원인을 알 수가 없어서 LangChain Github Repo를 들어가보나 13시간 전에 오류가 수정되어 있다든가... 여하튼 공부도 재밌지만 이런 초창기 프로젝트인 라이브러리를 이용해보는 경험 자체가 신비롭다.\n",
    "\n",
    "이런 개발 관련 블로그는 Ipython Notebook으로 작성하고 적당히 다듬은 후 (이것도 LLM으로 가능!) 올리는게 꽤 괜찮은 방법인 것 같다. 마침 테디 노트님이 해당 방법론에 대한 가이드도 만들어주셔서 보고 적용해보려 한다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "\n",
    "`langchain`을 `pip`로 설치해주기만 하면 된다. `langsmith` 설정은 나중에 필요성을 느낄 때 해도 늦지 않을 것 같아서 생략했다.\n",
    "\n",
    "LLM을 사용하기 위해서는 각 서비스에서 제공하는 API_KEY를 발급 받아야 한다. 이를 환경변수에 저장해두면 따로 파라미터로 전달하지 않고 편리하게 사용할 수 있다.\n",
    "\n",
    "테디노트에서는 `dotenv`를 사용하는데, 나는 그냥 귀찮아서  `.zprofile`에 (zsh 기준)에 등록했다. 주요 서비스 별 key는 다음과 같다.\n",
    "\n",
    "- OpenAI: `OPENAI_API_KEY`\n",
    "- Google Gemini: `GOOGLE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: content='대한민국의 수도는 서울입니다.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-4202b29e-4843-4a65-9de9-4591dc0852d3-0' usage_metadata={'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain과 LCEL(LangChain Expression Language) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{country}의 수도는 어디입니까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 `chain`은 `prompt`, `model`, `parser`의 sequential로 이루어진다. 각 요소는 용도에 따라 다양한 클래스로 구현되어 있으므로 필요에 따라 적절히 가져다 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디입니까?') middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10e60bc50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10e617590>, model_name='gpt-4o-mini', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')] last=StrOutputParser()\n",
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(chain)\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타입에서 알 수 있듯이 `chain`은 `Runnable`의 sequence이다. `prompt`, `model`, `parser`도 특정한 기능을 수행하고 있는 `Runnable`의 한 종류이다. 그렇기 때문에 아래 코드에서 각 요소들도 개별적으로 `invoke()` method를 호출 가능함을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='대한민국의 수도는 어디입니까?'\n",
      "content='대한민국의 수도는 서울입니다.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 13, 'total_tokens': 21}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-9c6f9ff5-699c-40ef-ac25-28cc70f33f5a-0' usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21}\n",
      "대한민국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke({\"country\": \"대한민국\"}))\n",
    "output = llm.invoke(\"대한민국의 수도는?\")\n",
    "print(output)\n",
    "print(output_parser.invoke(output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable\n",
    "\n",
    "chain을 효율적으로 구성하기 위해 연결고리 역할을 하는 `Runnable` 객체들이 있다.\n",
    "\n",
    "- `RunnablePassThrough`\n",
    "- `RunnableParalle`\n",
    "- `RunnableLambda`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassThrough"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 두 코드는 완전히 동일하다. 즉, `dict`를 chain에 포함시키고자 할 때 `RunnablePassThrough`를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='대한민국의 수도는?')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\n",
    "    prompt.invoke({\"country\":\"대한민국\"}) ==\n",
    "    ({\"country\": RunnablePassthrough()} | prompt).invoke(\"대한민국\")\n",
    ")\n",
    "\n",
    "prompt.invoke({\"country\":\"대한민국\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assign()` method를 이용하여, input으로 받은 `dict`에 새로운 키-밸류 쌍을 추가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '대한민국', 'city': '서울', 'address': '대한민국 서울'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 키: num, 할당(assign) 키: new_num\n",
    "(RunnablePassthrough.assign(address=lambda x: x[\"country\"] + \" \" +  x[\"city\"])).invoke({\"country\": \"대한민국\", \"city\": \"서울\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableParallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableParallel`은 input을 받으면, 이를 지정한 parameter 수 만큼의 `Runnable`(또는 callable, dict)에 전달하여 분기점을 형성하는 객체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out1': 1, 'out2': 2, 'out3': 3}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "RunnableParallel(out1=lambda x: x, out2=lambda x:x+1, out3=lambda x:x+2).invoke(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableParallel`을 이용하여 여러 개의 chain을 병렬적으로 연결할 수 있다.\n",
    "\n",
    "`RunnableParallel`로 chain을 연결할 경우 병렬처리되어 실행시간면에서 이득을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")\n",
    "\n",
    "chain1 = PromptTemplate.from_template(\"{country}의 수도는 어디입니까?\") | llm | StrOutputParser()\n",
    "chain2 = PromptTemplate.from_template(\"{country}의 인구는 몇 명입니까?\") | llm | StrOutputParser()\n",
    "chain3 = PromptTemplate.from_template(\"{country}의 면적은 얼마입니까?\") | llm | StrOutputParser()\n",
    "\n",
    "combined_chain = ({\"country\": RunnablePassthrough()} \n",
    "                  | RunnableParallel(capital=chain1, population=chain2, area=chain3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': '대한민국의 수도는 서울입니다.',\n",
       " 'population': '2023년 기준으로 대한민국의 인구는 약 5,100만 명 정도입니다. 하지만 인구는 지속적으로 변동하므로, 최신 통계는 대한민국 통계청이나 관련 기관의 공식 자료를 참고하는 것이 좋습니다.',\n",
       " 'area': '대한민국의 면적은 약 100,210 평방킬로미터입니다. 이는 한반도의 남쪽 부분에 해당하며, 북한과 함께 한반도를 구성하고 있습니다.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain.invoke(\"대한민국\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableLambda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnableLambda`를 사용하여 사용자 정의 함수를 맵핑할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 변수가 필요하지 않은 함수의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aug-04'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "print(get_today(None))\n",
    "\n",
    "RunnableLambda(get_today).invoke(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 변수가 1개인 함수의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "print(get_text_length(\"pizza\"))\n",
    "\n",
    "RunnableLambda(get_text_length).invoke(\"pizza\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 변수가 여러 개인 경우, 인수를 딕셔너리 하나로 받아서 원 함수를 호출하는 형태의 wrapping 함수를 재정의하여 활용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potato-pizza\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'potato-pizza'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_text(text1, text2):\n",
    "    return text1 + \"-\" + text2\n",
    "\n",
    "def _concat_text(_dict):\n",
    "    return concat_text(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "print(concat_text(\"potato\", \"pizza\"))\n",
    "\n",
    "RunnableLambda(_concat_text).invoke({\"text1\":\"potato\", \"text2\":\"pizza\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "굳이 함수를 재정의하지 않고 unpacking 연산자와 lambda를 활용하여 간단하게 작성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'potato-pizza'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_text(text1, text2):\n",
    "    return text1 + \"-\" + text2\n",
    "\n",
    "RunnableLambda(lambda _: concat_text(**_)).invoke({\"text1\":\"potato\", \"text2\":\"pizza\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "물론입니다! 8월 4일에 가까운 기념일들을 나열해 드리겠습니다:\n",
       "\n",
       "1. **8월 1일**: \n",
       "   - 스위스 국경일 (Swiss National Day)\n",
       "   - 세계 모유 수유 주간 (World Breastfeeding Week, 8월 1일 ~ 7일)\n",
       "\n",
       "2. **8월 6일**: \n",
       "   - 히로시마 원폭 투하 기념일 (Hiroshima Peace Memorial Ceremony)\n",
       "\n",
       "3. **8월 7일**: \n",
       "   - 퍼플 하트 데이 (Purple Heart Day, 미국)\n",
       "\n",
       "4. **8월 9일**: \n",
       "   - 나가사키 원폭 투하 기념일 (Nagasaki Peace Memorial Ceremony)\n",
       "   - 세계 원주민의 날 (International Day of the World's Indigenous Peoples)\n",
       "\n",
       "이 외에도 각 나라나 지역에 따라 다양한 기념일이 있을 수 있습니다. 특정 국가나 문화에 관련된 기념일을 알고 싶으시면 더 구체적으로 말씀해 주세요!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today)}\n",
    "    | PromptTemplate.from_template(\"{today}에 가까운 기념일을 나열해줘\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "display(Markdown(chain.invoke(\"\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
